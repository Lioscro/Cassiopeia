"""
This file stores a subclass of GreedySolver, the MaxCutGreedySolver. The
inference procedure here extends the "vanilla" Cassiopeia-Greedy, originally
proposed in Jones et al, Genome Biology (2020). After each putative split of
the samples generated by Cassioepia-Greedy, the hill-climbing prodecure from
the MaxCutSolver is applied to the partition to optimize the it for the 
max cut criterion on a connectivity graph built from the observed mutations 
in the samples representing a supertree of phylogentic trees on each 
individual character.
"""
import pandas as pd
from typing import Callable, Dict, List, Optional, Tuple, Union

from cassiopeia.solver import GreedySolver
from cassiopeia.solver import graph_utilities
from cassiopeia.solver.missing_data_methods import assign_missing_average


class MaxCutGreedySolver(GreedySolver.GreedySolver):
    """
    TODO: Implement fuzzy solver
    The MaxCutGreedySolver implements a top-down algorithm that recursively
    splits the sample set based on the presence/absence of the most frequent
    mutation. Additionally, the hill-climbing procedure from the MaxCutSolver is
    used to further optimize each split for the max cut on the similarity graph
    on the samples. This effectively moves samples across the partition so that
    samples with similar mutations are grouped together and samples with
    different mutations are seperated. Multiple missing data imputation methods
    are included for handling the case when a sample has a missing value on the
    character being split, where presence or absence of the character is
    ambiguous. The user can also specify a missing data method.

    Args:
        character_matrix: A character matrix of observed character states for
            all samples
        missing_char: The character representing missing values
        missing_data_classifier: Takes either a string specifying one of the
            included missing data imputation methods, or a function
            implementing the user-specified missing data method. The default is
            the "average" method
        meta_data: Any meta data associated with the samples
        priors: Prior probabilities of observing a transition from 0 to any
            state for each character
        prior_function: A function defining a transformation on the priors
            in forming weights to scale frequencies and the contribution of
            each mutuation in the connectivity graph

    Attributes:
        character_matrix: The character matrix describing the samples
        missing_char: The character representing missing values
        meta_data: Data table storing meta data for each sample
        priors: Prior probabilities of character state transitions
        weights: Weights on character/mutation pairs, derived from priors
        tree: The tree built by `self.solve()`. None if `solve` has not been
            called yet
        unique_character_matrix: A character matrix with duplicate rows filtered
            out
    """

    def __init__(
        self,
        character_matrix: pd.DataFrame,
        missing_char: int,
        missing_data_classifier: Union[Callable, str] = "average",
        meta_data: Optional[pd.DataFrame] = None,
        priors: Optional[Dict[int, Dict[int, float]]] = None,
        prior_function: Optional[Callable[[float], float]] = None,
    ):

        super().__init__(
            character_matrix, missing_char, meta_data, priors, prior_function
        )

        self.missing_data_classifier = missing_data_classifier

    def perform_split(
        self,
        mutation_frequencies: Dict[int, Dict[int, int]],
        samples: List[Union[int, str]],
    ) -> Tuple[List[Union[int, str]], List[Union[int, str]]]:
        """Performs a partition using both Greedy and MaxCut criteria.

        First, uses the most frequent (character, state) pair to split the list
        of samples. In doing so, the procedure makes use of the missing data
        classifier. Then, it optimizes this partition for the max cut on a
        connectivity graph constructed on the samples using a hill-climbing
        method.

        Args:
            mutation_frequencies: A dictionary containing the frequencies of
                each character/state pair that appear in the character matrix
                restricted to the sample set
            samples: A list of samples to partition

        Returns:
            A tuple of lists, representing the left and right partitions
        """
        best_frequency = 0
        chosen_character = 0
        chosen_state = 0
        for character in mutation_frequencies:
            for state in mutation_frequencies[character]:
                if state != self.missing_char and state != 0:
                    # Avoid splitting on mutations shared by all samples
                    if (
                        mutation_frequencies[character][state]
                        < len(samples)
                        - mutation_frequencies[character][self.missing_char]
                    ):
                        if self.weights:
                            if (
                                mutation_frequencies[character][state]
                                * self.weights[character][state]
                                > best_frequency
                            ):
                                chosen_character, chosen_state = (
                                    character,
                                    state,
                                )
                                best_frequency = (
                                    mutation_frequencies[character][state]
                                    * self.weights[character][state]
                                )
                        else:
                            if (
                                mutation_frequencies[character][state]
                                > best_frequency
                            ):
                                chosen_character, chosen_state = (
                                    character,
                                    state,
                                )
                                best_frequency = mutation_frequencies[
                                    character
                                ][state]

        if chosen_state == 0:
            return samples, []

        left_set = []
        right_set = []
        missing = []

        for i in samples:
            if (
                self.unique_character_matrix.loc[i, :][chosen_character]
                == chosen_state
            ):
                left_set.append(i)
            elif (
                self.unique_character_matrix.loc[i, :][chosen_character]
                == self.missing_char
            ):
                missing.append(i)
            else:
                right_set.append(i)

        if self.missing_data_classifier == "average":
            left_set, right_set = assign_missing_average(
                self.unique_character_matrix,
                self.missing_char,
                left_set,
                right_set,
                missing,
            )

        G = graph_utilities.construct_connectivity_graph(
            self.unique_character_matrix,
            mutation_frequencies,
            self.missing_char,
            samples,
            w=self.weights,
        )

        improved_left_set = graph_utilities.max_cut_improve_cut(G, left_set)

        improved_right_set = []
        for i in samples:
            if i not in improved_left_set:
                improved_right_set.append(i)

        return improved_left_set, improved_right_set
