{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pic\n",
    "import random\n",
    "\n",
    "import cassiopeia.TreeSolver.simulation_tools.simulation_utils as sim_utils\n",
    "import cassiopeia.TreeSolver.simulation_tools.dataset_generation as data_gen\n",
    "from cassiopeia.TreeSolver.Node import Node\n",
    "from cassiopeia.TreeSolver.Cassiopeia_Tree import Cassiopeia_Tree\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "\n",
    "#import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mutation(sample, mutation_prob_map):\n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        character = sample[i]\n",
    "        if character == '0':\n",
    "            values, probabilities = zip(*mutation_prob_map[i].items())\n",
    "            new_character = np.random.choice(values, p=probabilities)\n",
    "            new_sample.append(new_character)\n",
    "        else:\n",
    "            new_sample.append(character)\n",
    "    return new_sample\n",
    "\n",
    "def simulate_dropout(sample, variable_dropout_probability_map):\n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        if random.uniform(0, 1) <= variable_dropout_probability_map[i]:\n",
    "            new_sample.append('-')\n",
    "        else:\n",
    "            new_sample.append(sample[i])\n",
    "    return new_sample\n",
    "\n",
    "def get_character_matrix(nodes):\n",
    "    \n",
    "    char_arrays = []\n",
    "    for n in nodes:\n",
    "        chars = n.char_string.split(\"_\")[0].split(\"|\")\n",
    "        char_arrays.append(chars)\n",
    "        \n",
    "    return pd.DataFrame(char_arrays)\n",
    "\n",
    "def compute_priors(C, S, p, mean=0.01, disp=0.1, skew_factor = 0.05, num_skew=1, empirical = np.array([]), mixture = 0):\n",
    "    \n",
    "    sp = {}\n",
    "    prior_probabilities = {}\n",
    "    for i in range(0, C):\n",
    "        if len(empirical) > 0:\n",
    "            sampled_probabilities = sorted(empirical)\n",
    "        else:\n",
    "            sampled_probabilities = sorted([np.random.negative_binomial(mean,disp) for _ in range(1,S+1)])\n",
    "        s = C % num_skew\n",
    "        mut_rate = p * (1 + num_skew * skew_factor)\n",
    "        prior_probabilities[i] = {'0': (1-mut_rate)}\n",
    "        total = np.sum(sampled_probabilities)\n",
    "\n",
    "        sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "        \n",
    "        if mixture > 0: \n",
    "            for s in range(len(sampled_probabilities)):\n",
    "                if np.random.uniform() <= mixture:\n",
    "                    sampled_probabilities[s] = np.random.uniform()\n",
    "            \n",
    "            sp[i] = sampled_probabilities \n",
    "            total = np.sum(sampled_probabilities)\n",
    "            sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "            \n",
    "            \n",
    "        for j in range(1, S+1):\n",
    "            prior_probabilities[i][str(j)] = (mut_rate)*sampled_probabilities[j-1]\n",
    "\n",
    "    return prior_probabilities, sp\n",
    "\n",
    "def count_all_dropouts_leaves(leaves):\n",
    "    count = 0\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        for i in sample:\n",
    "            if (i == '-' or i == '*'):\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulated_ground_tree(mutation_prob_map, characters=10, depth=12, num_cells=400):\n",
    "    network = nx.DiGraph()\n",
    "    current_depth = [[['0' for _ in range(0, characters)], '0']]\n",
    "    network.add_node(sim_utils.node_to_string(current_depth[0]))\n",
    "    uniq = 1\n",
    "    for i in range(0, depth):\n",
    "        temp_current_depth = []\n",
    "        for node in current_depth:\n",
    "            for _ in range(0,2):\n",
    "                child_node = simulate_mutation(node[0], mutation_prob_map)\n",
    "                temp_current_depth.append([child_node, uniq])\n",
    "                network.add_edge(sim_utils.node_to_string(node), sim_utils.node_to_string([child_node, str(uniq)]))\n",
    "                uniq +=1\n",
    "\n",
    "        current_depth = temp_current_depth\n",
    "\n",
    "    rdict = {}\n",
    "    i = 0\n",
    "    for n in network.nodes:\n",
    "        nn = Node(\"StateNode\" + str(i), n.split(\"_\")[0].split(\"|\"), pid = n.split(\"_\")[1], is_target=False)\n",
    "        i += 1\n",
    "        rdict[n] = nn\n",
    "\n",
    "    network = nx.relabel_nodes(network, rdict)\n",
    "\n",
    "    leaves = [n for n in network if network.out_degree(n) == 0]\n",
    "    subsampled_population_for_removal = random.sample(leaves, len(leaves) - num_cells)\n",
    "    \n",
    "    for node in subsampled_population_for_removal:\n",
    "        network.remove_node(node)\n",
    "        \n",
    "    remaining = list(set(leaves)-set(subsampled_population_for_removal))\n",
    "\n",
    "    state_tree = Cassiopeia_Tree('simulated', network = network)\n",
    "    return state_tree, remaining\n",
    "\n",
    "def hereditary_helper(network, node, dropout_probability_map, hereditary_drop_indices, counter):\n",
    "    \n",
    "    sample = node.get_character_string().split('|')\n",
    "    temp_drop_indices = hereditary_drop_indices.copy()\n",
    "    \n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        if i in hereditary_drop_indices:\n",
    "            new_sample.append('*')\n",
    "        elif np.random.sample() <= dropout_probability_map[i]:\n",
    "            new_sample.append('*')\n",
    "            temp_drop_indices.append(i)\n",
    "            counter[0] = counter[0] + 1\n",
    "        else:\n",
    "            new_sample.append(sample[i])\n",
    "    \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "    \n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            hereditary_helper(network, i, dropout_probability_map, temp_drop_indices, counter)\n",
    "\n",
    "def stochastic_helper(network, node, dropout_probability_map, counter):\n",
    "    sample = node.get_character_string().split('|')\n",
    "    new_sample = simulate_dropout(sample, dropout_probability_map)\n",
    "    \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "    \n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            stochastic_helper(network, i, dropout_probability_map, counter)\n",
    "            \n",
    "def stochastic_helper_leaves(leaves, dropout_probability_map, counter):\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        new_sample = simulate_dropout(sample, dropout_probability_map)\n",
    "    \n",
    "        node.char_vec = new_sample\n",
    "        node.char_string = '|'.join([str(c) for c in new_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters. 'hdropout_percent' is a string that represents the dropout percent, for pathing purposes\n",
    "\n",
    "no_mut_rate = .985\n",
    "number_of_states = 40\n",
    "dropout = 0.02\n",
    "depth = 11\n",
    "number_of_characters = 40\n",
    "NUM_CELLS = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_map = {\"0\": 0.00, \"1\": 0.01, \"2\": 0.02, \"3\": 0.03, \"4\": 0.04, \"5\": 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "0 0.021016666666666666\n",
      "1 0.020416666666666666\n",
      "2 0.02036666666666667\n",
      "3 0.020116666666666668\n",
      "4 0.020483333333333333\n",
      "5 0.021116666666666666\n",
      "6 0.020616666666666665\n",
      "7 0.02036666666666667\n",
      "8 0.019966666666666667\n",
      "9 0.019683333333333334\n",
      "10 0.0195\n",
      "11 0.0192\n",
      "12 0.0199\n",
      "13 0.020166666666666666\n",
      "14 0.020033333333333334\n",
      "15 0.0192\n",
      "16 0.0194\n",
      "17 0.019916666666666666\n",
      "18 0.019583333333333335\n",
      "19 0.020216666666666668\n",
      "20 0.0194\n",
      "21 0.019766666666666665\n",
      "22 0.01945\n",
      "23 0.020016666666666665\n",
      "24 0.019683333333333334\n",
      "25 0.0192\n",
      "26 0.0204\n",
      "27 0.020216666666666668\n",
      "28 0.01975\n",
      "29 0.020083333333333335\n",
      "30 0.020516666666666666\n",
      "31 0.01965\n",
      "32 0.019616666666666668\n",
      "33 0.020066666666666667\n",
      "34 0.0197\n",
      "35 0.01995\n",
      "36 0.01948333333333333\n",
      "37 0.020483333333333333\n",
      "38 0.019266666666666668\n",
      "39 0.0209\n",
      "40 0.01975\n",
      "41 0.019916666666666666\n",
      "42 0.020983333333333333\n",
      "43 0.020483333333333333\n",
      "44 0.0199\n",
      "45 0.018966666666666666\n",
      "46 0.01955\n",
      "47 0.019683333333333334\n",
      "48 0.019033333333333333\n",
      "49 0.019633333333333332\n",
      "1\n",
      "0.01\n",
      "0 0.12271666666666667\n",
      "1 0.09226666666666666\n",
      "2 0.13915\n",
      "3 0.14415\n",
      "4 0.12738333333333332\n",
      "5 0.13116666666666665\n",
      "6 0.16486666666666666\n",
      "7 0.14053333333333334\n",
      "8 0.1365\n",
      "9 0.12851666666666667\n",
      "10 0.1514\n",
      "11 0.1061\n",
      "12 0.1269\n",
      "13 0.12163333333333333\n",
      "14 0.13928333333333334\n",
      "15 0.13823333333333335\n",
      "16 0.10438333333333333\n",
      "17 0.13278333333333334\n",
      "18 0.11175\n",
      "19 0.12558333333333332\n",
      "20 0.14943333333333333\n",
      "21 0.12541666666666668\n",
      "22 0.12773333333333334\n",
      "23 0.14615\n",
      "24 0.12425\n",
      "25 0.11136666666666667\n",
      "26 0.12573333333333334\n",
      "27 0.18153333333333332\n",
      "28 0.12493333333333333\n",
      "29 0.09628333333333333\n",
      "30 0.11891666666666667\n",
      "31 0.1088\n",
      "32 0.14041666666666666\n",
      "33 0.14116666666666666\n",
      "34 0.11365\n",
      "35 0.17223333333333332\n",
      "36 0.11301666666666667\n",
      "37 0.1316\n",
      "38 0.106\n",
      "39 0.13598333333333334\n",
      "40 0.15006666666666665\n",
      "41 0.13946666666666666\n",
      "42 0.13543333333333332\n",
      "43 0.10906666666666667\n",
      "44 0.13231666666666667\n",
      "45 0.1399\n",
      "46 0.17113333333333333\n",
      "47 0.11568333333333333\n",
      "48 0.15223333333333333\n",
      "49 0.14858333333333335\n",
      "2\n",
      "0.02\n",
      "0 0.19956666666666667\n",
      "1 0.22938333333333333\n",
      "2 0.2291\n",
      "3 0.1985\n",
      "4 0.25333333333333335\n",
      "5 0.23256666666666667\n",
      "6 0.21675\n",
      "7 0.20956666666666668\n",
      "8 0.23378333333333334\n",
      "9 0.2377\n",
      "10 0.22926666666666667\n",
      "11 0.30551666666666666\n",
      "12 0.2171\n",
      "13 0.2218\n",
      "14 0.26061666666666666\n",
      "15 0.24273333333333333\n",
      "16 0.24823333333333333\n",
      "17 0.22721666666666668\n",
      "18 0.21493333333333334\n",
      "19 0.23898333333333333\n",
      "20 0.27085\n",
      "21 0.1988\n",
      "22 0.25283333333333335\n",
      "23 0.22811666666666666\n",
      "24 0.23\n",
      "25 0.23653333333333335\n",
      "26 0.226\n",
      "27 0.24523333333333333\n",
      "28 0.21938333333333335\n",
      "29 0.22056666666666666\n",
      "30 0.25115\n",
      "31 0.24053333333333332\n",
      "32 0.23535\n",
      "33 0.21038333333333334\n",
      "34 0.18651666666666666\n",
      "35 0.23655\n",
      "36 0.24271666666666666\n",
      "37 0.20703333333333335\n",
      "38 0.23261666666666667\n",
      "39 0.21288333333333334\n",
      "40 0.20973333333333333\n",
      "41 0.22131666666666666\n",
      "42 0.2343\n",
      "43 0.23828333333333335\n",
      "44 0.23461666666666667\n",
      "45 0.19961666666666666\n",
      "46 0.25685\n",
      "47 0.22601666666666667\n",
      "48 0.18336666666666668\n",
      "49 0.24808333333333332\n",
      "3\n",
      "0.03\n",
      "0 0.3363\n",
      "1 0.3318833333333333\n",
      "2 0.3491166666666667\n",
      "3 0.3450666666666667\n",
      "4 0.3061333333333333\n",
      "5 0.28576666666666667\n",
      "6 0.3037666666666667\n",
      "7 0.31346666666666667\n",
      "8 0.37316666666666665\n",
      "9 0.3393833333333333\n",
      "10 0.30961666666666665\n",
      "11 0.30335\n",
      "12 0.30135\n",
      "13 0.32711666666666667\n",
      "14 0.30028333333333335\n",
      "15 0.31605\n",
      "16 0.3433833333333333\n",
      "17 0.2966\n",
      "18 0.3866\n",
      "19 0.31153333333333333\n",
      "20 0.2755666666666667\n",
      "21 0.3554\n",
      "22 0.28345\n",
      "23 0.3127333333333333\n",
      "24 0.30345\n",
      "25 0.3342\n",
      "26 0.30456666666666665\n",
      "27 0.29638333333333333\n",
      "28 0.29001666666666664\n",
      "29 0.29555\n",
      "30 0.31833333333333336\n",
      "31 0.3322333333333333\n",
      "32 0.29923333333333335\n",
      "33 0.36328333333333335\n",
      "34 0.29351666666666665\n",
      "35 0.35975\n",
      "36 0.28408333333333335\n",
      "37 0.2900333333333333\n",
      "38 0.34928333333333333\n",
      "39 0.37033333333333335\n",
      "40 0.3487166666666667\n",
      "41 0.34858333333333336\n",
      "42 0.35778333333333334\n",
      "43 0.35861666666666664\n",
      "44 0.34775\n",
      "45 0.3582166666666667\n",
      "46 0.32181666666666664\n",
      "47 0.2819333333333333\n",
      "48 0.29346666666666665\n",
      "49 0.31976666666666664\n",
      "4\n",
      "0.04\n",
      "0 0.4048833333333333\n",
      "1 0.3920666666666667\n",
      "2 0.3739\n",
      "3 0.43615\n",
      "4 0.42436666666666667\n",
      "5 0.41925\n",
      "6 0.39968333333333333\n",
      "7 0.4308\n",
      "8 0.37378333333333336\n",
      "9 0.3716333333333333\n",
      "10 0.39823333333333333\n",
      "11 0.3551666666666667\n",
      "12 0.36743333333333333\n",
      "13 0.3859166666666667\n",
      "14 0.42405\n",
      "15 0.3809166666666667\n",
      "16 0.39668333333333333\n",
      "17 0.39641666666666664\n",
      "18 0.4084\n",
      "19 0.44103333333333333\n",
      "20 0.37528333333333336\n",
      "21 0.35833333333333334\n",
      "22 0.3499833333333333\n",
      "23 0.4197\n",
      "24 0.39503333333333335\n",
      "25 0.41515\n",
      "26 0.3550833333333333\n",
      "27 0.3836833333333333\n",
      "28 0.43633333333333335\n",
      "29 0.4267166666666667\n",
      "30 0.3819666666666667\n",
      "31 0.36593333333333333\n",
      "32 0.3961166666666667\n",
      "33 0.39841666666666664\n",
      "34 0.43745\n",
      "35 0.37738333333333335\n",
      "36 0.44693333333333335\n",
      "37 0.4572\n",
      "38 0.44503333333333334\n",
      "39 0.4438166666666667\n",
      "40 0.3784666666666667\n",
      "41 0.45038333333333336\n",
      "42 0.36301666666666665\n",
      "43 0.37146666666666667\n",
      "44 0.4055666666666667\n",
      "45 0.3434833333333333\n",
      "46 0.37905\n",
      "47 0.4125\n",
      "48 0.3991166666666667\n",
      "49 0.42006666666666664\n",
      "5\n",
      "0.05\n",
      "0 0.4152666666666667\n",
      "1 0.4706\n",
      "2 0.49828333333333336\n",
      "3 0.42685\n",
      "4 0.4405\n",
      "5 0.45568333333333333\n",
      "6 0.48946666666666666\n",
      "7 0.4774\n",
      "8 0.5096833333333334\n",
      "9 0.4890833333333333\n",
      "10 0.4894\n",
      "11 0.5402333333333333\n",
      "12 0.45511666666666667\n",
      "13 0.45111666666666667\n",
      "14 0.48236666666666667\n",
      "15 0.4209333333333333\n",
      "16 0.4297666666666667\n",
      "17 0.47363333333333335\n",
      "18 0.47383333333333333\n",
      "19 0.45813333333333334\n",
      "20 0.4078\n",
      "21 0.4397333333333333\n",
      "22 0.42441666666666666\n",
      "23 0.4844833333333333\n",
      "24 0.50455\n",
      "25 0.5422333333333333\n",
      "26 0.4483666666666667\n",
      "27 0.4538\n",
      "28 0.42445\n",
      "29 0.4565666666666667\n",
      "30 0.45361666666666667\n",
      "31 0.4957166666666667\n",
      "32 0.49283333333333335\n",
      "33 0.42833333333333334\n",
      "34 0.41573333333333334\n",
      "35 0.49905\n",
      "36 0.46881666666666666\n",
      "37 0.49895\n",
      "38 0.4755\n",
      "39 0.47968333333333335\n",
      "40 0.4417833333333333\n",
      "41 0.5102666666666666\n",
      "42 0.44066666666666665\n",
      "43 0.49565\n",
      "44 0.43173333333333336\n",
      "45 0.42993333333333333\n",
      "46 0.5064333333333333\n",
      "47 0.5129\n",
      "48 0.5134333333333333\n",
      "49 0.47938333333333333\n"
     ]
    }
   ],
   "source": [
    "for hdropout_percent in dropout_map:\n",
    "\n",
    "    hdropout = dropout_map[hdropout_percent]\n",
    "    \n",
    "    print(hdropout_percent)\n",
    "    print(hdropout)\n",
    "\n",
    "    #Create dropout maps\n",
    "    dropouts = pd.DataFrame(np.full((number_of_characters, 1), dropout, dtype=float))\n",
    "    dropout_prob_map = {i: dropout for i in range(0,number_of_characters)}\n",
    "    hdropout_prob_map = {i: hdropout for i in range(0,number_of_characters)}\n",
    "\n",
    "    #Establish the path, and create it if it doesn't yet exist\n",
    "    path = \"/data/yosef2/users/richardz/projects/dropout_testing/heritable_testing/\" + str(NUM_CELLS) + \"cells/\" + hdropout_percent + \"percent\"\n",
    "    if os.path.exists(path) == False:\n",
    "        os.mkdir(path)\n",
    "\n",
    "    #Main loop for simulation\n",
    "    counts = []\n",
    "    for i in range(0, 50):\n",
    "\n",
    "        #Compute Priors and generate the simulated tree\n",
    "        prior_probabilities = compute_priors(number_of_characters, number_of_states, 1-no_mut_rate, 5, 0.5, skew_factor=0.0, num_skew=1)[0]\n",
    "        out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=number_of_characters, num_cells = NUM_CELLS, depth=depth)\n",
    "        #     pic.dump(out, open('/data/yosef2/users/richardz/projects/dropout_testing/ground_truth_testing/ground_truth_tree' + str(i) + '.pkl', 'wb'))\n",
    "        network = out.get_network()\n",
    "        #     pic.dump(out, open(path + '/sim_net' + str(i) + '.pkl', 'wb'))\n",
    "        pic.dump(prior_probabilities, open(path + '/sim_net_priors' + str(i) + '.pkl', 'wb'))\n",
    "\n",
    "        #Save the ground truth character matrix\n",
    "        ground_cm = get_character_matrix(leaves)\n",
    "        ground_cm.to_csv(path + '/ground_truth_cm' + str(i) + '.txt', sep = '\\t')\n",
    "\n",
    "        #Introduce both stochastic and heritable dropout\n",
    "        root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "        counter = [0]\n",
    "        stochastic_helper_leaves(leaves, dropout_prob_map, counter)\n",
    "        counter2 = [0]\n",
    "        hereditary_helper(network, root, hdropout_prob_map, [], counter2)\n",
    "\n",
    "        #Create the character matrix post dropout, giving names to the indeces\n",
    "        dropout_cm = get_character_matrix(leaves)\n",
    "        dropout_cm = dropout_cm.astype(str)\n",
    "        row_names = ['c' + str(i) for i in range(dropout_cm.shape[0])]\n",
    "        dropout_cm.index = row_names\n",
    "        dropout_cm.to_csv(path + '/dropout_cm' + str(i) + '.txt', sep = '\\t')\n",
    "        pic.dump(out, open(path + '/dropout_net' + str(i) + '.pkl', 'wb'))\n",
    "\n",
    "        #Count the dropout proportion and save it\n",
    "        count = count_all_dropouts_leaves(leaves)/(NUM_CELLS*number_of_states)\n",
    "        counts.append(count)\n",
    "        print(i, count)\n",
    "\n",
    "    import csv\n",
    "\n",
    "    #Write the dropout proportions to CSV\n",
    "    with open('/data/yosef2/users/richardz/projects/dropout_testing/heritable_testing/' + str(NUM_CELLS) + 'cells/dropout_percentage' + hdropout_percent + '.csv', 'w') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerow(counts)\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "i = 1\n",
    "prior_probabilities = compute_priors(number_of_characters, number_of_states, 1-no_mut_rate, 5, 0.5, skew_factor=0.0, num_skew=1)[0]\n",
    "out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=number_of_characters, num_cells = NUM_CELLS, depth=depth)\n",
    "\n",
    "network = out.get_network()\n",
    "ground_cm = get_character_matrix(leaves)\n",
    "\n",
    "root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "counter = [0]\n",
    "stochastic_helper(network, root, dropout_prob_map, counter)\n",
    "counter2 = [0]\n",
    "hereditary_helper(network, root, hdropout_prob_map, [], counter2)\n",
    "\n",
    "dropout_cm = get_character_matrix(leaves)\n",
    "dropout_cm = dropout_cm.astype(str)\n",
    "row_names = ['c' + str(i) for i in range(dropout_cm.shape[0])]\n",
    "dropout_cm.index = row_names\n",
    "\n",
    "count = count_all_dropouts_leaves(leaves)/(NUM_CELLS*number_of_states)\n",
    "counts.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "path = \"/data/yosef2/users/richardz/projects/benchmarking/test_bench_imp/100_chars_h_drop_sample\"\n",
    "if os.path.exists(path) == False:\n",
    "    os.mkdir(path)\n",
    "    \n",
    "for num in range(0, 10):\n",
    "    prior_probabilities = {}\n",
    "    dist = {'0': 0.9}\n",
    "    for i in range(1, 11):\n",
    "        dist[str(i)] = 0.01\n",
    "    for i in range(0, 100):\n",
    "        prior_probabilities[i] = dist\n",
    "        \n",
    "    dropout = .04\n",
    "    hdropout = .02\n",
    "    dropout_prob_map = {i: dropout for i in range(0,100)}\n",
    "    hdropout_prob_map = {i: hdropout for i in range(0,100)}\n",
    "    out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=100, num_cells = 512, depth=9)\n",
    "    print(len(leaves))\n",
    "    #     pic.dump(out, open('/data/yosef2/users/richardz/projects/dropout_testing/ground_truth_testing/ground_truth_tree' + str(i) + '.pkl', 'wb'))\n",
    "    network = out.get_network()\n",
    "\n",
    "    #Save the ground truth character matrix\n",
    "    ground_cm = get_character_matrix(leaves)\n",
    "    ground_cm.to_csv(path + '/ground_truth_cm' + str(num) + '.txt', sep = '\\t')\n",
    "\n",
    "    # #Introduce both stochastic and heritable dropout\n",
    "    root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "    counter = [0]\n",
    "    stochastic_helper_leaves(leaves, dropout_prob_map, counter)\n",
    "    counter2 = [0]\n",
    "    hereditary_helper(network, root, hdropout_prob_map, [], counter2)\n",
    "\n",
    "    #Create the character matrix post dropout, giving names to the indeces\n",
    "    dropout_cm = get_character_matrix(leaves)\n",
    "    dropout_cm = dropout_cm.astype(str)\n",
    "    row_names = ['c' + str(i) for i in range(dropout_cm.shape[0])]\n",
    "    dropout_cm.index = row_names\n",
    "    dropout_cm.to_csv(path + '/dropout_cm' + str(num) + '.txt', sep = '\\t')\n",
    "    pic.dump(out, open(path + '/dropout_net' + str(num) + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/data/yosef2/users/richardz/projects/benchmarking/test_bench_imp/100_chars_h_drop_sample/dropout_cm10.txt' does not exist: b'/data/yosef2/users/richardz/projects/benchmarking/test_bench_imp/100_chars_h_drop_sample/dropout_cm10.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f03394bb74d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# for i in range(1, 101):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'dropout_cm'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#     cm = pd.read_csv(path + 'lg' + str(i) + '/lg' + str(i) + '_character_matrix.txt', sep = '\\t', index_col = 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/data/yosef2/users/richardz/projects/benchmarking/test_bench_imp/100_chars_h_drop_sample/dropout_cm10.txt' does not exist: b'/data/yosef2/users/richardz/projects/benchmarking/test_bench_imp/100_chars_h_drop_sample/dropout_cm10.txt'"
     ]
    }
   ],
   "source": [
    "num_cells = 400\n",
    "path = \"/data/yosef2/users/richardz/projects/benchmarking/test_bench_imp/100_chars_h_drop_sample/\"\n",
    "# path = \"/data/yosef2/users/mattjones/projects/metastasis/JQ19/5k/trees/\"\n",
    "\n",
    "drop_perc_i = []\n",
    "stoch_perc_i = []\n",
    "herit_perc_i = []\n",
    "mut_perc_i = []\n",
    "max_spc_i = []\n",
    "avg_spc_i = []\n",
    "size_i = []\n",
    "num_chars_i = []\n",
    "\n",
    "counter = 0\n",
    "# for i in range(1, 101):\n",
    "for i in range(0, 50):\n",
    "    cm = pd.read_csv(path + 'dropout_cm' + str(i) + '.txt', sep = '\\t', index_col = 0)\n",
    "#     cm = pd.read_csv(path + 'lg' + str(i) + '/lg' + str(i) + '_character_matrix.txt', sep = '\\t', index_col = 0)\n",
    "\n",
    "    to_remove = []\n",
    "    for i in range(cm.shape[1]):\n",
    "        val = ((cm.iloc[:,i] == '-').sum() + (cm.iloc[:,i] == '*').sum())/cm.shape[0]\n",
    "        if val > 1:\n",
    "            to_remove.append('c' + str(i))\n",
    "            \n",
    "    counter += len(to_remove)\n",
    "    \n",
    "#     print(list(cm.index.values))\n",
    "    cm.drop(to_remove, inplace = True)\n",
    "\n",
    "    num_dropped = (cm.values == '-').sum() + (cm.values == '*').sum()\n",
    "    stoch_perc_i.append((cm.values == '-').sum()/num_dropped)\n",
    "    herit_perc_i.append((cm.values == '*').sum()/num_dropped)\n",
    "    num_mut = cm.shape[0] * cm.shape[1] - num_dropped - (cm.values == '0').sum()\n",
    "    drop_perc_i.append(num_dropped/(cm.shape[0] * cm.shape[1]))\n",
    "    mut_perc_i.append(num_mut/(cm.shape[0] * cm.shape[1] - num_dropped))\n",
    "    \n",
    "#     spc = bd.states_per_char(cm)\n",
    "#     avg_spc_i.append(sum(spc)/len(spc))\n",
    "#     max_spc_i.append(max(spc))\n",
    "    \n",
    "    size_i.append(cm.shape[0])\n",
    "    num_chars_i.append(cm.shape[1])\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8472683647102252,\n",
       " 0.845756180092114,\n",
       " 0.8353664487166975,\n",
       " 0.8295669487307118,\n",
       " 0.8338186759852456,\n",
       " 0.8280579131303045,\n",
       " 0.8045536759229706,\n",
       " 0.8559885078110971,\n",
       " 0.8294036061026352,\n",
       " 0.8231171651367091]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.2,\n",
       " 1: 0.2,\n",
       " 2: 0.2,\n",
       " 3: 0.2,\n",
       " 4: 0.2,\n",
       " 5: 0.2,\n",
       " 6: 0.2,\n",
       " 7: 0.2,\n",
       " 8: 0.2,\n",
       " 9: 0.2,\n",
       " 10: 0.2,\n",
       " 11: 0.2,\n",
       " 12: 0.2,\n",
       " 13: 0.2,\n",
       " 14: 0.2,\n",
       " 15: 0.2,\n",
       " 16: 0.2,\n",
       " 17: 0.2,\n",
       " 18: 0.2,\n",
       " 19: 0.2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = .2\n",
    "dropout_prob_map = {i: dropout for i in range(0,20)}\n",
    "dropout_prob_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
