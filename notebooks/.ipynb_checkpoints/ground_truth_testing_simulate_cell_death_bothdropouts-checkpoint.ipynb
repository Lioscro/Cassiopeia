{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pic\n",
    "import random\n",
    "\n",
    "import cassiopeia.TreeSolver.simulation_tools.simulation_utils as sim_utils\n",
    "import cassiopeia.TreeSolver.simulation_tools.dataset_generation as data_gen\n",
    "from cassiopeia.TreeSolver.Node import Node\n",
    "from cassiopeia.TreeSolver.Cassiopeia_Tree import Cassiopeia_Tree\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "\n",
    "#import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mutation(sample, mutation_prob_map):\n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        character = sample[i]\n",
    "        if character == '0':\n",
    "            values, probabilities = zip(*mutation_prob_map[i].items())\n",
    "            new_character = np.random.choice(values, p=probabilities)\n",
    "            new_sample.append(new_character)\n",
    "        else:\n",
    "            new_sample.append(character)\n",
    "    return new_sample\n",
    "\n",
    "def simulate_dropout(sample, variable_dropout_probability_map):\n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        if random.uniform(0, 1) <= variable_dropout_probability_map[i]:\n",
    "            new_sample.append('-')\n",
    "        else:\n",
    "            new_sample.append(sample[i])\n",
    "    return new_sample\n",
    "\n",
    "def get_character_matrix(nodes):\n",
    "    \n",
    "    char_arrays = []\n",
    "    for n in nodes:\n",
    "        chars = n.char_string.split(\"_\")[0].split(\"|\")\n",
    "        char_arrays.append(chars)\n",
    "        \n",
    "    return pd.DataFrame(char_arrays)\n",
    "\n",
    "def compute_priors(C, S, p, mean=0.01, disp=0.1, skew_factor = 0.05, num_skew=1, empirical = np.array([]), mixture = 0):\n",
    "    \n",
    "    sp = {}\n",
    "    prior_probabilities = {}\n",
    "    for i in range(0, C):\n",
    "        if len(empirical) > 0:\n",
    "            sampled_probabilities = sorted(empirical)\n",
    "        else:\n",
    "            sampled_probabilities = sorted([np.random.negative_binomial(mean,disp) for _ in range(1,S+1)])\n",
    "        s = C % num_skew\n",
    "        mut_rate = p * (1 + num_skew * skew_factor)\n",
    "        prior_probabilities[i] = {'0': (1-mut_rate)}\n",
    "        total = np.sum(sampled_probabilities)\n",
    "\n",
    "        sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "        \n",
    "        if mixture > 0: \n",
    "            for s in range(len(sampled_probabilities)):\n",
    "                if np.random.uniform() <= mixture:\n",
    "                    sampled_probabilities[s] = np.random.uniform()\n",
    "            \n",
    "            sp[i] = sampled_probabilities \n",
    "            total = np.sum(sampled_probabilities)\n",
    "            sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "            \n",
    "            \n",
    "        for j in range(1, S+1):\n",
    "            prior_probabilities[i][str(j)] = (mut_rate)*sampled_probabilities[j-1]\n",
    "\n",
    "    return prior_probabilities, sp\n",
    "\n",
    "def count_all_dropouts_leaves(leaves):\n",
    "    count = 0\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        for i in sample:\n",
    "            if (i == '-' or i == '*'):\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulated_ground_tree(mutation_prob_map, characters=10, depth=10, min_division_rate=0.8, cell_death=0.01):\n",
    "    network = nx.DiGraph()\n",
    "    current_depth = [[['0' for _ in range(0, characters)], '0']]\n",
    "    network.add_node(sim_utils.node_to_string(current_depth[0]))\n",
    "    uniq = 1\n",
    "    \n",
    "#     division_rate = min_division_rate+((1-min_division_rate)*np.random.random())\n",
    "    division_rate = min_division_rate\n",
    "    \n",
    "    for i in range(0, depth):\n",
    "        temp_current_depth = []\n",
    "        for node in current_depth:\n",
    "            if np.random.random() >= cell_death:\n",
    "                if np.random.random() <= division_rate:\n",
    "                    for _ in range(0,2):\n",
    "                        child_node = simulate_mutation(node[0], mutation_prob_map)\n",
    "                        temp_current_depth.append([child_node, uniq])\n",
    "                        network.add_edge(sim_utils.node_to_string(node), sim_utils.node_to_string([child_node, str(uniq)]))\n",
    "                        uniq +=1\n",
    "                else:\n",
    "                    child_node = simulate_mutation(node[0], mutation_prob_map)\n",
    "                    temp_current_depth.append([child_node, node[1]])\n",
    "                    network = nx.relabel_nodes(network, {sim_utils.node_to_string(node): sim_utils.node_to_string([child_node, node[1]])}, copy = False)\n",
    "            else:\n",
    "                curr_parent = sim_utils.node_to_string(node)\n",
    "                while network.out_degree(curr_parent) < 1 and network.in_degree(curr_parent) > 0:\n",
    "                    next_parent = list(network.predecessors(curr_parent))[0]\n",
    "                    network.remove_node(curr_parent)\n",
    "                    curr_parent = next_parent\n",
    "                \n",
    "        current_depth = temp_current_depth\n",
    "\n",
    "    rdict = {}\n",
    "    i = 0\n",
    "    for n in network.nodes:\n",
    "        nn = Node(\"StateNode\" + str(i), n.split(\"_\")[0].split(\"|\"), pid = n.split(\"_\")[1], is_target=False)\n",
    "        i += 1\n",
    "        rdict[n] = nn\n",
    "\n",
    "    network = nx.relabel_nodes(network, rdict)\n",
    "    \n",
    "#     source = [x for x in network.nodes() if network.in_degree(x)==0][0]\n",
    "\n",
    "#     max_depth = max(nx.shortest_path_length(network,source,node) for node in network.nodes())\n",
    "#     shortest_paths = nx.shortest_path_length(network,source)\n",
    "\n",
    "#     leaves = [x for x in network.nodes() if network.out_degree(x)==0 and network.in_degree(x) == 1 and shortest_paths[x] == max_depth]\n",
    "\n",
    "    leaves = [n for n in network if network.out_degree(n) == 0 and network.in_degree(n) == 1] \n",
    "    \n",
    "    state_tree = Cassiopeia_Tree('simulated', network = network)\n",
    "    return state_tree, leaves\n",
    "\n",
    "def hereditary_helper(network, node, dropout_probability_map, hereditary_drop_indices, counter):\n",
    "    \n",
    "    sample = node.get_character_string().split('|')\n",
    "    temp_drop_indices = hereditary_drop_indices.copy()\n",
    "    \n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        if i in hereditary_drop_indices:\n",
    "            new_sample.append('-')\n",
    "        elif np.random.sample() <= dropout_probability_map[i]:\n",
    "            new_sample.append('-')\n",
    "            temp_drop_indices.append(i)\n",
    "            counter[0] = counter[0] + 1\n",
    "        else:\n",
    "            new_sample.append(sample[i])\n",
    "    \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "    \n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            hereditary_helper(network, i, dropout_probability_map, temp_drop_indices, counter)\n",
    "\n",
    "def stochastic_helper(network, node, dropout_probability_map, counter):\n",
    "    sample = node.get_character_string().split('|')\n",
    "    new_sample = simulate_dropout(sample, dropout_probability_map)\n",
    "    \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "    \n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            stochastic_helper(network, i, dropout_probability_map, counter)\n",
    "            \n",
    "def stochastic_helper_leaves(leaves, dropout_probability_map, counter):\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        new_sample = simulate_dropout(sample, dropout_probability_map)\n",
    "    \n",
    "        node.char_vec = new_sample\n",
    "        node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "        \n",
    "def states_per_char(cm):\n",
    "    unique_chars = [0 for n in range(0, cm.shape[1])]\n",
    "    seen = [[] for n in range(0, cm.shape[1])]\n",
    "    for j in range(0, cm.shape[1]):\n",
    "        for i in range(0,cm.shape[0]):\n",
    "            val = cm.iloc[i, j]\n",
    "            if val != '0' and val != '-' and val not in seen[j]:\n",
    "                unique_chars[j] += 1\n",
    "                seen[j].append(val)\n",
    "    return unique_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters. 'hdropout_percent' is a string that represents the dropout percent, for pathing purposes\n",
    "\n",
    "NUM_CELLS = 1500\n",
    "mut_rate = .0075\n",
    "number_of_states = 100\n",
    "depth = 11\n",
    "number_of_characters = 30\n",
    "death_rate = 0.06\n",
    "s_dropout = 0.20\n",
    "h_dropout = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout_map = {\"0\": 0.00, \"1\": 0.01, \"2\": 0.02, \"3\": 0.03, \"4\": 0.04, \"5\": 0.05, \"7\": 0.07, \"10\": 0.10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1973941368078176 307 4.4\n",
      "1 0.20445344129554655 494 7.266666666666667\n",
      "2 0.197667638483965 343 4.733333333333333\n",
      "3 0.203637713437268 449 6.9\n",
      "4 0.20352831940575672 359 5.266666666666667\n",
      "5 0.19723661485319516 386 6.233333333333333\n",
      "6 0.20103703703703704 450 6.433333333333334\n",
      "7 0.20443906376109766 413 5.366666666666666\n",
      "8 0.20082815734989648 322 4.266666666666667\n",
      "9 0.19944903581267218 363 5.233333333333333\n",
      "10 0.20286396181384247 419 6.3\n",
      "11 0.19896331738437 418 6.466666666666667\n",
      "12 0.2036649214659686 382 6.0\n",
      "13 0.20582922824302136 406 6.266666666666667\n",
      "14 0.20061162079510703 327 4.533333333333333\n",
      "15 0.20229120473022913 451 6.8\n",
      "16 0.20317052270779778 389 5.2\n",
      "17 0.19941666666666666 400 6.433333333333334\n",
      "18 0.19853479853479852 364 5.5\n",
      "19 0.20135021097046413 395 5.8\n",
      "20 0.2044041450777202 386 5.3\n",
      "21 0.20149476831091181 446 6.5\n",
      "22 0.2019753086419753 405 6.0\n",
      "23 0.19841740850642928 337 4.3\n",
      "24 0.20704761904761904 350 5.433333333333334\n",
      "25 0.2009933774834437 302 5.133333333333334\n",
      "26 0.20522522522522524 370 4.966666666666667\n",
      "27 0.2018322762508809 473 6.866666666666666\n",
      "28 0.19646182495344505 358 5.8\n",
      "29 0.20394173093401885 389 5.433333333333334\n",
      "30 0.19880382775119618 418 5.966666666666667\n",
      "31 0.20555555555555555 312 3.9\n",
      "32 0.20426457789382071 383 5.5\n",
      "33 0.2000697350069735 478 7.9\n",
      "34 0.1971737323358271 401 6.133333333333334\n",
      "35 0.202504816955684 346 5.133333333333334\n",
      "36 0.20109649122807016 304 5.566666666666666\n",
      "37 0.21317460317460318 420 6.066666666666666\n",
      "38 0.1994579945799458 369 4.933333333333334\n",
      "39 0.20742705570291778 377 5.9\n",
      "40 0.20112449799196788 415 6.566666666666666\n",
      "41 0.20411985018726592 445 7.166666666666667\n",
      "42 0.20389513108614232 445 6.333333333333333\n",
      "43 0.20040849673202615 408 5.633333333333334\n",
      "44 0.19525089605734766 372 5.933333333333334\n",
      "45 0.19839255499153977 394 6.033333333333333\n",
      "46 0.1989920806335493 463 7.533333333333333\n",
      "47 0.20188834154351396 406 5.433333333333334\n",
      "48 0.20304347826086958 460 6.666666666666667\n",
      "49 0.20596285434995112 341 4.9\n"
     ]
    }
   ],
   "source": [
    "# for dropout_str in dropout_map:\n",
    "\n",
    "#     dropout = dropout_map[dropout_str]\n",
    "#     print(dropout_str)\n",
    "\n",
    "#     #Create dropout maps\n",
    "#     dropouts = pd.DataFrame(np.full((number_of_characters, 1), dropout, dtype=float))\n",
    "s_dropout_prob_map = {i: s_dropout for i in range(0,number_of_characters)}\n",
    "h_dropout_prob_map = {i: h_dropout for i in range(0,number_of_characters)}\n",
    "\n",
    "#Establish the path, and create it if it doesn't yet exist\n",
    "path = \"/data/yosef2/users/richardz/projects/Yule/benchmarking/old_sim\"\n",
    "if os.path.exists(path) == False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "#Main loop for simulation\n",
    "counts = []\n",
    "size = []\n",
    "avg_spc = []\n",
    "for i in range(0, 50):\n",
    "\n",
    "    #Compute Priors and generate the simulated tree\n",
    "    prior_probabilities = compute_priors(number_of_characters, number_of_states, mut_rate, 5, 0.5, skew_factor=0.0, num_skew=1)[0]\n",
    "    out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=number_of_characters, depth=depth, min_division_rate= 0.7, cell_death = death_rate)\n",
    "    #     pic.dump(out, open('/data/yosef2/users/richardz/projects/dropout_testing/ground_truth_testing/ground_truth_tree' + str(i) + '.pkl', 'wb'))\n",
    "    while len(leaves) < 300 or len(leaves) > 500:\n",
    "        out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=number_of_characters, depth=depth, min_division_rate= 0.8, cell_death = death_rate)\n",
    "        \n",
    "    network = out.get_network()\n",
    "    #     pic.dump(out, open(path + '/sim_net' + str(i) + '.pkl', 'wb'))\n",
    "    pic.dump(prior_probabilities, open(path + '/sim_net_priors' + str(i) + '.pkl', 'wb'))\n",
    "\n",
    "    #Save the ground truth character matrix\n",
    "    ground_cm = get_character_matrix(leaves)\n",
    "    ground_cm.to_csv(path + '/ground_truth_cm' + str(i) + '.txt', sep = '\\t')\n",
    "\n",
    "    #Introduce Stochastic Dropout\n",
    "    root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "    counter = [0]\n",
    "    stochastic_helper_leaves(leaves, s_dropout_prob_map, counter)\n",
    "    counter2 = [0]\n",
    "    hereditary_helper(network, root, h_dropout_prob_map, [], counter2)\n",
    "\n",
    "    #Create the character matrix post dropout, giving names to the indeces\n",
    "    dropout_cm = get_character_matrix(leaves)\n",
    "    dropout_cm = dropout_cm.astype(str)\n",
    "    row_names = ['c' + str(i) for i in range(dropout_cm.shape[0])]\n",
    "    dropout_cm.index = row_names\n",
    "    dropout_cm.to_csv(path + '/dropout_cm' + str(i) + '.txt', sep = '\\t')\n",
    "    pic.dump(out, open(path + '/dropout_net' + str(i) + '.pkl', 'wb'))\n",
    "\n",
    "    #Count the dropout proportion and save it\n",
    "    num_leaves = len(leaves)\n",
    "    size.append(num_leaves)\n",
    "\n",
    "    count = count_all_dropouts_leaves(leaves)/(num_leaves*number_of_characters)\n",
    "    counts.append(count)\n",
    "    \n",
    "    spc = states_per_char(dropout_cm)\n",
    "    avg_spc.append(sum(spc)/len(spc))\n",
    "\n",
    "    print(i, count, num_leaves, sum(spc)/len(spc))\n",
    "\n",
    "# import csv\n",
    "\n",
    "# #Write the dropout proportions to CSV\n",
    "# with open('/data/yosef2/users/richardz/projects/dropout_testing/cell_death_testing_new_both/dropout_percentage' + dropout_str + '.csv', 'w') as csvFile:\n",
    "#     writer = csv.writer(csvFile)\n",
    "#     writer.writerow(counts)\n",
    "# csvFile.close()\n",
    "\n",
    "# with open('/data/yosef2/users/richardz/projects/dropout_testing/cell_death_testing_new_both/sample_size' + dropout_str + '.csv', 'w') as csvFile:\n",
    "#     writer = csv.writer(csvFile)\n",
    "#     writer.writerow(size)\n",
    "# csvFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.806666666666667\n",
      "5.85\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "print(stat.mean(avg_spc))\n",
    "print(stat.median(avg_spc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2018153573601391\n",
      "0.20166352228089635\n"
     ]
    }
   ],
   "source": [
    "print(stat.mean(counts))\n",
    "print(stat.median(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392.2\n",
      "391.5\n"
     ]
    }
   ],
   "source": [
    "print(stat.mean(size))\n",
    "print(stat.median(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
