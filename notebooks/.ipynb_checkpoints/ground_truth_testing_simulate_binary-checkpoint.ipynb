{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pic\n",
    "import random\n",
    "\n",
    "import cassiopeia.TreeSolver.simulation_tools.simulation_utils as sim_utils\n",
    "import cassiopeia.TreeSolver.simulation_tools.dataset_generation as data_gen\n",
    "from cassiopeia.TreeSolver.Node import Node\n",
    "from cassiopeia.TreeSolver.Cassiopeia_Tree import Cassiopeia_Tree\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "\n",
    "#import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mutation(sample, mutation_prob_map):\n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        character = sample[i]\n",
    "        if character == '0':\n",
    "            values, probabilities = zip(*mutation_prob_map[i].items())\n",
    "            new_character = np.random.choice(values, p=probabilities)\n",
    "            new_sample.append(new_character)\n",
    "        else:\n",
    "            new_sample.append(character)\n",
    "    return new_sample\n",
    "\n",
    "def simulate_dropout(sample, variable_dropout_probability_map):\n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        if random.uniform(0, 1) <= variable_dropout_probability_map[i]:\n",
    "            new_sample.append('-')\n",
    "        else:\n",
    "            new_sample.append(sample[i])\n",
    "    return new_sample\n",
    "\n",
    "def get_character_matrix(nodes):\n",
    "    \n",
    "    char_arrays = []\n",
    "    for n in nodes:\n",
    "        chars = n.char_string.split(\"_\")[0].split(\"|\")\n",
    "        char_arrays.append(chars)\n",
    "        \n",
    "    return pd.DataFrame(char_arrays)\n",
    "\n",
    "compute_priors(number_of_characters, number_of_states, 1-no_mut_rate, 5, 0.5, skew_factor=0.0, num_skew=1)[0]\n",
    "\n",
    "def compute_priors(C, S, p, mean=0.01, disp=0.1, skew_factor = 0.05, num_skew=1, empirical = np.array([]), mixture = 0):\n",
    "    \n",
    "    sp = {}\n",
    "    prior_probabilities = {}\n",
    "    for i in range(0, C):\n",
    "        if len(empirical) > 0:\n",
    "            sampled_probabilities = sorted(empirical)\n",
    "        else:\n",
    "            sampled_probabilities = sorted([np.random.negative_binomial(mean,disp) for _ in range(1,S+1)])\n",
    "        s = C % num_skew\n",
    "        mut_rate = p * (1 + num_skew * skew_factor)\n",
    "        prior_probabilities[i] = {'0': (1-mut_rate)}\n",
    "        total = np.sum(sampled_probabilities)\n",
    "\n",
    "        sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "        \n",
    "        if mixture > 0: \n",
    "            for s in range(len(sampled_probabilities)):\n",
    "                if np.random.uniform() <= mixture:\n",
    "                    sampled_probabilities[s] = np.random.uniform()\n",
    "            \n",
    "            sp[i] = sampled_probabilities \n",
    "            total = np.sum(sampled_probabilities)\n",
    "            sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "            \n",
    "            \n",
    "        for j in range(1, S+1):\n",
    "            prior_probabilities[i][str(j)] = (mut_rate)*sampled_probabilities[j-1]\n",
    "\n",
    "    return prior_probabilities, sp\n",
    "\n",
    "def count_all_dropouts_leaves(leaves):\n",
    "    count = 0\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        for i in sample:\n",
    "            if (i == '-' or i == '*'):\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulated_ground_tree(mutation_prob_map, characters=10, depth=10, min_division_rate=0.8, cell_death=0.01):\n",
    "    network = nx.DiGraph()\n",
    "    current_depth = [[['0' for _ in range(0, characters)], '0']]\n",
    "    network.add_node(sim_utils.node_to_string(current_depth[0]))\n",
    "    uniq = 1\n",
    "    \n",
    "    division_rate = min_division_rate+((1-min_division_rate)*np.random.random())\n",
    "    \n",
    "    for i in range(0, depth):\n",
    "        temp_current_depth = []\n",
    "        for node in current_depth:\n",
    "            if np.random.random() >= cell_death:\n",
    "                if np.random.random() <= division_rate:\n",
    "                    for _ in range(0,2):\n",
    "                        child_node = simulate_mutation(node[0], mutation_prob_map)\n",
    "                        temp_current_depth.append([child_node, uniq])\n",
    "                        network.add_edge(sim_utils.node_to_string(node), sim_utils.node_to_string([child_node, str(uniq)]))\n",
    "                        uniq +=1\n",
    "                else:\n",
    "                    child_node = simulate_mutation(node[0], mutation_prob_map)\n",
    "                    temp_current_depth.append([child_node, node[1]])\n",
    "                    network = nx.relabel_nodes(network, {sim_utils.node_to_string(node): sim_utils.node_to_string([child_node, node[1]])}, copy = False)\n",
    "            else:\n",
    "                curr_parent = sim_utils.node_to_string(node)\n",
    "                while network.out_degree(curr_parent) < 1 and network.in_degree(curr_parent) > 0:\n",
    "                    next_parent = list(network.predecessors(curr_parent))[0]\n",
    "                    network.remove_node(curr_parent)\n",
    "                    curr_parent = next_parent\n",
    "                \n",
    "        current_depth = temp_current_depth\n",
    "\n",
    "    rdict = {}\n",
    "    i = 0\n",
    "    for n in network.nodes:\n",
    "        nn = Node(\"StateNode\" + str(i), n.split(\"_\")[0].split(\"|\"), pid = n.split(\"_\")[1], is_target=False)\n",
    "        i += 1\n",
    "        rdict[n] = nn\n",
    "\n",
    "    network = nx.relabel_nodes(network, rdict)\n",
    "    \n",
    "#     source = [x for x in network.nodes() if network.in_degree(x)==0][0]\n",
    "\n",
    "#     max_depth = max(nx.shortest_path_length(network,source,node) for node in network.nodes())\n",
    "#     shortest_paths = nx.shortest_path_length(network,source)\n",
    "\n",
    "#     leaves = [x for x in network.nodes() if network.out_degree(x)==0 and network.in_degree(x) == 1 and shortest_paths[x] == max_depth]\n",
    "\n",
    "    leaves = [n for n in network if network.out_degree(n) == 0 and network.in_degree(n) == 1] \n",
    "    \n",
    "    state_tree = Cassiopeia_Tree('simulated', network = network)\n",
    "    return state_tree, leaves\n",
    "\n",
    "def hereditary_helper(network, node, dropout_probability_map, hereditary_drop_indices, counter):\n",
    "    \n",
    "    sample = node.get_character_string().split('|')\n",
    "    temp_drop_indices = hereditary_drop_indices.copy()\n",
    "    \n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        if i in hereditary_drop_indices:\n",
    "            new_sample.append('-')\n",
    "        elif np.random.sample() <= dropout_probability_map[i]:\n",
    "            new_sample.append('-')\n",
    "            temp_drop_indices.append(i)\n",
    "            counter[0] = counter[0] + 1\n",
    "        else:\n",
    "            new_sample.append(sample[i])\n",
    "    \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "    \n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            hereditary_helper(network, i, dropout_probability_map, temp_drop_indices, counter)\n",
    "\n",
    "def stochastic_helper(network, node, dropout_probability_map, counter):\n",
    "    sample = node.get_character_string().split('|')\n",
    "    new_sample = simulate_dropout(sample, dropout_probability_map)\n",
    "    \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "    \n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            stochastic_helper(network, i, dropout_probability_map, counter)\n",
    "            \n",
    "def stochastic_helper_leaves(leaves, dropout_probability_map, counter):\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        new_sample = simulate_dropout(sample, dropout_probability_map)\n",
    "    \n",
    "        node.char_vec = new_sample\n",
    "        node.char_string = '|'.join([str(c) for c in new_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters. 'hdropout_percent' is a string that represents the dropout percent, for pathing purposes\n",
    "\n",
    "NUM_CELLS = 1500\n",
    "no_mut_rate = .985\n",
    "number_of_states = 1\n",
    "depth = 11\n",
    "number_of_characters = 40\n",
    "death_rate = 0.2\n",
    "dropout = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.018852459016393444 244\n",
      "1 0.01834061135371179 229\n",
      "2 0.019302325581395347 215\n",
      "3 0.020135746606334843 221\n",
      "4 0.018039443155452438 431\n",
      "5 0.020044052863436124 227\n",
      "6 0.020023148148148148 216\n",
      "7 0.0215311004784689 209\n",
      "8 0.02185185185185185 270\n",
      "9 0.019029850746268655 268\n"
     ]
    }
   ],
   "source": [
    "#Create dropout maps\n",
    "dropouts = pd.DataFrame(np.full((number_of_characters, 1), dropout, dtype=float))\n",
    "dropout_prob_map = {i: dropout for i in range(0,number_of_characters)}\n",
    "\n",
    "#Establish the path, and create it if it doesn't yet exist\n",
    "path = \"/data/yosef2/users/richardz/projects/dropout_testing/binary_stoch_only\"\n",
    "if os.path.exists(path) == False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "#Main loop for simulation\n",
    "counts = []\n",
    "size = []\n",
    "for i in range(0, 50):\n",
    "\n",
    "    #Compute Priors and generate the simulated tree\n",
    "    prior_probabilites = {}\n",
    "    for k in range(0, number_of_characters):\n",
    "        prior_probabilities[k] = {'0': 0.985, '1': 0.015}\n",
    "    #prior_probabilities = compute_priors(number_of_characters, number_of_states, 1-no_mut_rate, 5, 0.5, skew_factor=0.0, num_skew=1)[0]\n",
    "    out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=number_of_characters, depth=depth, min_division_rate= 0.8, cell_death = death_rate)\n",
    "    #     pic.dump(out, open('/data/yosef2/users/richardz/projects/dropout_testing/ground_truth_testing/ground_truth_tree' + str(i) + '.pkl', 'wb'))\n",
    "    while len(leaves) < 200:\n",
    "        out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=number_of_characters, depth=depth, min_division_rate= 0.8, cell_death = death_rate)\n",
    "\n",
    "    network = out.get_network()\n",
    "    #     pic.dump(out, open(path + '/sim_net' + str(i) + '.pkl', 'wb'))\n",
    "    pic.dump(prior_probabilities, open(path + '/sim_net_priors' + str(i) + '.pkl', 'wb'))\n",
    "\n",
    "    #Save the ground truth character matrix\n",
    "    ground_cm = get_character_matrix(leaves)\n",
    "    ground_cm.to_csv(path + '/ground_truth_cm' + str(i) + '.txt', sep = '\\t')\n",
    "\n",
    "    #Introduce Stochastic Dropout\n",
    "    root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "    counter = [0]\n",
    "    stochastic_helper_leaves(leaves, dropout_prob_map, counter)\n",
    "#     counter2 = [0]\n",
    "#     hereditary_helper(network, root, dropout_prob_map, [], counter2)\n",
    "\n",
    "    #Create the character matrix post dropout, giving names to the indeces\n",
    "    dropout_cm = get_character_matrix(leaves)\n",
    "    dropout_cm = dropout_cm.astype(str)\n",
    "    row_names = ['c' + str(i) for i in range(dropout_cm.shape[0])]\n",
    "    dropout_cm.index = row_names\n",
    "    dropout_cm.to_csv(path + '/dropout_cm' + str(i) + '.txt', sep = '\\t')\n",
    "    pic.dump(out, open(path + '/dropout_net' + str(i) + '.pkl', 'wb'))\n",
    "\n",
    "    #Count the dropout proportion and save it\n",
    "    num_leaves = len(leaves)\n",
    "    size.append(num_leaves)\n",
    "\n",
    "    count = count_all_dropouts_leaves(leaves)/(num_leaves*number_of_characters)\n",
    "    counts.append(count)\n",
    "\n",
    "    print(i, count, num_leaves)\n",
    "\n",
    "import csv\n",
    "\n",
    "#Write the dropout proportions to CSV\n",
    "with open('/data/yosef2/users/richardz/projects/dropout_testing/binary_stoch_only/dropout_amounts.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow(counts)\n",
    "csvFile.close()\n",
    "\n",
    "with open('/data/yosef2/users/richardz/projects/dropout_testing/binary_stoch_only/sample_sizes.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow(size)\n",
    "csvFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
