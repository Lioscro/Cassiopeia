{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pic\n",
    "import random\n",
    "\n",
    "import cassiopeia.TreeSolver.simulation_tools.simulation_utils as sim_utils\n",
    "import cassiopeia.TreeSolver.simulation_tools.dataset_generation as data_gen\n",
    "from cassiopeia.TreeSolver.Node import Node\n",
    "from cassiopeia.TreeSolver.Cassiopeia_Tree import Cassiopeia_Tree\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "\n",
    "#import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_matrix(nodes):\n",
    "    \n",
    "    char_arrays = []\n",
    "    for n in nodes:\n",
    "        chars = n.char_string.split(\"_\")[0].split(\"|\")\n",
    "        char_arrays.append(chars)\n",
    "        \n",
    "    return pd.DataFrame(char_arrays)\n",
    "\n",
    "def compute_priors(C, S, p, mean=0.01, disp=0.1, skew_factor = 0.05, num_skew=1, empirical = np.array([]), mixture = 0):\n",
    "    \n",
    "    sp = {}\n",
    "    prior_probabilities = {}\n",
    "    for i in range(0, C):\n",
    "        if len(empirical) > 0:\n",
    "            sampled_probabilities = sorted(empirical)\n",
    "        else:\n",
    "            sampled_probabilities = sorted([np.random.negative_binomial(mean,disp) for _ in range(1,S+1)])\n",
    "        s = C % num_skew\n",
    "        mut_rate = p * (1 + num_skew * skew_factor)\n",
    "        prior_probabilities[i] = {'0': (1-mut_rate)}\n",
    "        total = np.sum(sampled_probabilities)\n",
    "\n",
    "        sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "        \n",
    "        if mixture > 0: \n",
    "            for s in range(len(sampled_probabilities)):\n",
    "                if np.random.uniform() <= mixture:\n",
    "                    sampled_probabilities[s] = np.random.uniform()\n",
    "            \n",
    "            sp[i] = sampled_probabilities \n",
    "            total = np.sum(sampled_probabilities)\n",
    "            sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "            \n",
    "            \n",
    "        for j in range(1, S+1):\n",
    "            prior_probabilities[i][str(j)] = (mut_rate)*sampled_probabilities[j-1]\n",
    "\n",
    "    return prior_probabilities, sp\n",
    "\n",
    "def count_all_dropouts_leaves(leaves):\n",
    "    count = 0\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        for i in sample:\n",
    "            if (i == '-' or i == '*'):\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mutation(network, mutation_prob_map, basal_rate, cassette_size):\n",
    "    root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "    mutation_cache = {}\n",
    "    \n",
    "    for i in mutation_prob_map: #edit the mutation map to only include the probs \n",
    "                                #of mutating to each state, given that character is chosen to mutate\n",
    "        sum = 0\n",
    "        mutation_prob_map[i].pop('0', None)\n",
    "        for j in mutation_prob_map[i]:\n",
    "            sum += mutation_prob_map[i][j]\n",
    "        new_probs = {}\n",
    "        for j in mutation_prob_map[i]:\n",
    "            new_probs[j] = mutation_prob_map[i][j]/sum\n",
    "        mutation_prob_map[i] = new_probs\n",
    "    \n",
    "    mutation_prob_map['basal_mut_rate'] = basal_rate\n",
    "    \n",
    "    mutation_helper(network, root, mutation_prob_map, mutation_cache, root.char_vec, [], cassette_size)\n",
    "\n",
    "def mutation_helper(network, node, mutation_prob_map, mutation_cache, curr_mutations, dropout_indices, cassette_size):\n",
    "    new_sample = curr_mutations.copy()\n",
    "    new_dropout_indices = dropout_indices.copy()\n",
    "    t = network.nodes[node]['lifespan']\n",
    "    if t == 0:\n",
    "        node.char_vec = new_sample\n",
    "        node.char_string = '|'.join([str(char) for char in new_sample])\n",
    "        network.nodes[node]['dropout'] = new_dropout_indices\n",
    "        return\n",
    "    mut_rate = mutation_prob_map['basal_mut_rate']\n",
    "    p = 0\n",
    "    \n",
    "    if len(mutation_cache) == 0:\n",
    "        mutation_cache[1] = mut_rate\n",
    "    \n",
    "    if t in mutation_cache:\n",
    "        p = mutation_cache[t]\n",
    "    else:\n",
    "        t_p = max(mutation_cache.keys())\n",
    "        p = mutation_cache[t_p]\n",
    "        for t_temp in range(t_p + 1, t + 1):\n",
    "            p += mut_rate * (1 - mut_rate) ** (t_temp - 1)\n",
    "            mutation_cache[t_temp] = p\n",
    "            \n",
    "    base_chars = []\n",
    "    for i in range(0, len(new_sample)):\n",
    "        if new_sample[i] == '0' and i not in new_dropout_indices:\n",
    "            base_chars.append(i)\n",
    "    \n",
    "    times = {}\n",
    "    draws = np.random.binomial(len(base_chars), p)\n",
    "    chosen_ind = np.random.choice(base_chars, draws)\n",
    "    for i in chosen_ind:\n",
    "        values, probabilities = zip(*mutation_prob_map[i].items())\n",
    "        new_character = np.random.choice(values, p=probabilities)\n",
    "        new_sample[i] = new_character\n",
    "        time = np.random.choice(range(1, t + 1))\n",
    "        for ti in range(time - 2, time + 3):\n",
    "            if ti >= 1 and ti <= t:\n",
    "                if ti in times:\n",
    "                    times[ti].append(i)\n",
    "                else:\n",
    "                    times[ti] = [i]\n",
    "    \n",
    "    for time in sorted(times.keys()):\n",
    "        if len(times[time]) > 1:\n",
    "            not_dropped = []\n",
    "            for i in times[time]:\n",
    "                if i not in new_dropout_indices:\n",
    "                    not_dropped.append(i)\n",
    "            for c in range(0, (len(new_sample)//cassette_size)):\n",
    "                cass_indices = []\n",
    "                for i in not_dropped:\n",
    "                    if (i >= c * cassette_size and i < (c + 1) * cassette_size):\n",
    "                        cass_indices.append(i)\n",
    "                if len(cass_indices) > 1:\n",
    "                    for e in range(min(cass_indices), max(cass_indices) + 1):\n",
    "                        new_dropout_indices.append(e)\n",
    "             \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(char) for char in new_sample])\n",
    "    network.nodes[node]['dropout'] = new_dropout_indices\n",
    "\n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            mutation_helper(network, i, mutation_prob_map, mutation_cache, new_sample, new_dropout_indices, cassette_size)\n",
    "\n",
    "def overlay_heritable_dropout(network):\n",
    "    root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "    h_dropout_helper(network, root)\n",
    "\n",
    "def h_dropout_helper(network, node):\n",
    "    new_sample = node.char_vec.copy()\n",
    "    for i in network.nodes[node]['dropout']:\n",
    "        new_sample[i] = '-'\n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(char) for char in new_sample])\n",
    "\n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            h_dropout_helper(network, i)\n",
    "            \n",
    "def add_stochastic_leaves(leaves, dropout_prob, cassette_size):\n",
    "    for node in leaves:\n",
    "        sample = node.char_vec.copy()\n",
    "        for i in range(0, len(sample)//cassette_size):\n",
    "            if random.uniform(0, 1) <= dropout_prob:\n",
    "                for j in range(i * cassette_size, (i + 1) * cassette_size):\n",
    "                    sample[j] = '-'\n",
    "        node.char_vec = sample\n",
    "        node.char_string = '|'.join([str(char) for char in sample])\n",
    "        \n",
    "# def mutation_helper_old(network, node, mutation_prob_map, mutation_cache, curr_mutations):\n",
    "#     new_sample = curr_mutations\n",
    "#     t = network.nodes[node]['lifespan']\n",
    "#     for i in range(0, len(new_sample)):\n",
    "#         if new_sample[i] == '0':\n",
    "#             values, probabilities = zip(*mutation_prob_map[i].items())\n",
    "#             if t in mutation_cache[i]:\n",
    "#                 new_probs = mutation_cache[i][t]\n",
    "#             else:\n",
    "#                 new_probs = []\n",
    "#                 t_p = 0\n",
    "#                 if len(mutation_cache) == 0:\n",
    "#                     t_p = 1\n",
    "#                     new_probs = probabilities\n",
    "#                 else:\n",
    "#                     t_p = max(mutation_cache[i])\n",
    "#                     new_probs = mutation_cache[i][t_p]\n",
    "#                 for t_temp in range(t_p, t + 1):\n",
    "#                     new_probs[0] *= probabilities[0]\n",
    "#                     for p in range(1, len(new_probs)):\n",
    "#                         new_probs += probabilities[0] ** (t_temp - 1) * probabilities[p]\n",
    "#                     mutation_cache[i][t_temp] = new_probs\n",
    "#             new_character = np.random.choice(values, p=new_probs)\n",
    "#             new_sample[i] = new_character\n",
    "#     node.char_vec = new_sample\n",
    "#     node.char_string = '|'.join([str(char) for char in new_sample])\n",
    "    \n",
    "#     if network.out_degree(node) > 0:\n",
    "#         for i in network.successors(node):\n",
    "#             mutation_helper(network, i, mutation_prob_map, mutation_cache, new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phylo_forward_pass(\n",
    "    cassette_size = 3,\n",
    "    cassette_number = 10,\n",
    "    timesteps = 100, \n",
    "    min_division_rate = 0.076,\n",
    "    #U = lambda: np.random.exponential(1, 1),\n",
    "    fitness_rate = 0.000,\n",
    "    epsilon = 0.001,\n",
    "    cell_death = 0.001\n",
    "):\n",
    "    \n",
    "    characters = cassette_size * cassette_number\n",
    "    \n",
    "#     division_rate = min_division_rate + np.random.exponential(1, 1) * (1 - min_division_rate) # probability that cell will double per time-step\n",
    "    division_rate = min_division_rate\n",
    "    \n",
    "    network = nx.DiGraph()\n",
    "    current_cells = [[['0' for _ in range(0, characters)], '0']]\n",
    "    \n",
    "    network.add_node(sim_utils.node_to_string(current_cells[0]))\n",
    "    network.nodes[sim_utils.node_to_string(current_cells[0])]['fitness'] = division_rate\n",
    "    network.nodes[sim_utils.node_to_string(current_cells[0])]['lifespan'] = 0\n",
    "    uniq = 1\n",
    "    \n",
    "    for t in range(0, timesteps + 1):\n",
    "        temp_current_cells = []\n",
    "#         if len(current_cells) == 0:\n",
    "#             print(\"all cells dead, terminating\")\n",
    "#             break\n",
    "#         current_fitnesses = [network.nodes[sim_utils.node_to_string(n)]['fitness'] for n in current_cells]\n",
    "#         norm = np.max(current_fitnesses)\n",
    "        \n",
    "        for node in current_cells:\n",
    "            fitness = network.nodes[sim_utils.node_to_string(node)]['fitness']\n",
    "            network.nodes[sim_utils.node_to_string(node)]['lifespan'] += 1\n",
    "            \n",
    "            if np.random.random() >= cell_death:\n",
    "                \n",
    "                if np.random.random() <= fitness_rate: #cell gains a fitness mutation\n",
    "#                     if t == (timesteps - 1):\n",
    "#                         network.node[node]['fitness'] = fitness\n",
    "#                     else:\n",
    "#                     s = max(1e-20, U()[0])\n",
    "                    if np.random.random() <= 0.5:\n",
    "                        fitness = fitness + epsilon\n",
    "                    else:\n",
    "                        fitness = fitness - epsilon\n",
    "                    network.nodes[sim_utils.node_to_string(node)]['fitness'] = fitness\n",
    "                \n",
    "                if np.random.random() <= fitness: # t != (timesteps - 1): #cell divides\n",
    "                    for _ in range(0,2):\n",
    "                        parent_fitness = network.nodes[sim_utils.node_to_string(node)]['fitness']\n",
    "                        temp_current_cells.append([node[0], str(uniq)])\n",
    "                        network.add_edge(sim_utils.node_to_string(node), sim_utils.node_to_string([node[0], str(uniq)]))\n",
    "                        network.nodes[sim_utils.node_to_string([node[0], str(uniq)])]['fitness'] = parent_fitness\n",
    "                        network.nodes[sim_utils.node_to_string([node[0], str(uniq)])]['lifespan'] = 0\n",
    "                        uniq += 1\n",
    "                else: #cell does not divide\n",
    "                    temp_current_cells.append(node)\n",
    "                                    \n",
    "            else: #if cell dies\n",
    "                curr_parent = sim_utils.node_to_string(node)\n",
    "                while network.out_degree(curr_parent) < 1 and network.in_degree(curr_parent) > 0:\n",
    "                    next_parent = list(network.predecessors(curr_parent))[0]\n",
    "                    network.remove_node(curr_parent)\n",
    "                    curr_parent = next_parent\n",
    "                \n",
    "        current_cells = temp_current_cells\n",
    "#         print(\"timestep:\" + str(t))\n",
    "#         print(\"size:\" + str(len(current_cells)))\n",
    "        \n",
    "    rdict = {}\n",
    "    i = 0\n",
    "    for n in network.nodes:\n",
    "        nn = Node(\"StateNode\" + str(i), n.split(\"_\")[0].split(\"|\"), pid = n.split(\"_\")[1], is_target=False)\n",
    "        i += 1\n",
    "        rdict[n] = nn\n",
    "\n",
    "    network = nx.relabel_nodes(network, rdict)\n",
    "    \n",
    "#     source = [x for x in network.nodes() if network.in_degree(x)==0][0]\n",
    "\n",
    "#     max_depth = max(nx.shortest_path_length(network,source,node) for node in network.nodes())\n",
    "#     shortest_paths = nx.shortest_path_length(network,source)\n",
    "\n",
    "#     leaves = [x for x in network.nodes() if network.out_degree(x)==0 and network.in_degree(x) == 1 and shortest_paths[x] == max_depth]\n",
    "\n",
    "    leaves = [n for n in network if network.out_degree(n) == 0 and network.in_degree(n) == 1] \n",
    "    \n",
    "    state_tree = Cassiopeia_Tree('simulated', network = network)\n",
    "    return state_tree, leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def states_per_char(cm):\n",
    "    unique_chars = [0 for n in range(0, cm.shape[1])]\n",
    "    seen = [[] for n in range(0, cm.shape[1])]\n",
    "    for j in range(0, cm.shape[1]):\n",
    "        for i in range(0,cm.shape[0]):\n",
    "            val = cm.iloc[i, j]\n",
    "            if val != '0' and val != '-' and val not in seen[j]:\n",
    "                unique_chars[j] += 1\n",
    "                seen[j].append(val)\n",
    "    return unique_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 336 4.866666666666666\n",
      "2 347 4.633333333333334\n",
      "3 334 5.5\n",
      "4 489 7.366666666666666\n",
      "5 481 7.0\n",
      "6 344 5.266666666666667\n",
      "7 355 5.566666666666666\n",
      "8 396 6.233333333333333\n",
      "9 348 4.366666666666666\n",
      "10 445 6.9\n",
      "11 339 5.4\n",
      "12 487 6.2\n",
      "13 309 4.7\n",
      "14 442 6.8\n",
      "15 328 5.0\n",
      "16 348 5.333333333333333\n",
      "17 358 5.2\n",
      "18 416 6.933333333333334\n",
      "19 362 4.466666666666667\n",
      "20 410 6.833333333333333\n",
      "21 434 7.266666666666667\n",
      "22 395 7.1\n",
      "23 417 6.233333333333333\n",
      "24 331 5.6\n",
      "25 341 5.433333333333334\n",
      "26 399 5.4\n",
      "27 384 5.333333333333333\n",
      "28 346 5.333333333333333\n",
      "29 491 6.5\n",
      "30 306 4.366666666666666\n",
      "31 495 6.9\n",
      "32 403 6.033333333333333\n",
      "33 436 7.133333333333334\n",
      "34 377 5.166666666666667\n",
      "35 383 6.1\n",
      "36 366 5.933333333333334\n",
      "37 316 4.166666666666667\n",
      "38 370 5.433333333333334\n",
      "39 404 4.966666666666667\n",
      "40 479 7.7\n",
      "41 349 5.033333333333333\n",
      "42 468 7.966666666666667\n",
      "43 476 7.933333333333334\n",
      "44 466 5.966666666666667\n",
      "45 325 3.8666666666666667\n",
      "46 361 5.433333333333334\n",
      "47 419 6.633333333333334\n",
      "48 413 5.566666666666666\n",
      "49 418 6.833333333333333\n",
      "50 320 4.166666666666667\n"
     ]
    }
   ],
   "source": [
    "path = \"/data/yosef2/users/richardz/projects/Yule/benchmarking/t500\"\n",
    "if os.path.exists(path) == False:\n",
    "    os.mkdir(path)  \n",
    "\n",
    "timesteps = 500\n",
    "division_rate = 0.0166\n",
    "fitness_rate = 0.0025\n",
    "epsilon = 0.001\n",
    "cell_death = 0.006\n",
    "mutation_rate = 0.00026\n",
    "cassette_size = 3\n",
    "dropout_rate = 0.20\n",
    "\n",
    "# counts = []\n",
    "size = []\n",
    "drop_perc = []\n",
    "avg_spc = []\n",
    "\n",
    "# avg_unique_chars = []\n",
    "for i in range(1, 51):\n",
    "    out, leaves = phylo_forward_pass(timesteps = timesteps, \n",
    "                                          min_division_rate = division_rate, \n",
    "                                          fitness_rate = fitness_rate, \n",
    "                                          epsilon = epsilon, \n",
    "                                          cell_death = cell_death)\n",
    "    \n",
    "    while len(leaves) < 300 or len(leaves) > 500:\n",
    "        out, leaves = phylo_forward_pass(timesteps = timesteps, \n",
    "                                              min_division_rate = division_rate, \n",
    "                                              fitness_rate = fitness_rate, \n",
    "                                              epsilon = epsilon,\n",
    "                                              cell_death = cell_death)\n",
    "\n",
    "    prior_probabilities = compute_priors(30, 100, mutation_rate, 5, 0.5, skew_factor=0.0, num_skew=1)[0]\n",
    "    \n",
    "    pic.dump(prior_probabilities, open(path + '/priors' + str(i) + '.pkl', 'wb'))\n",
    "    \n",
    "    overlay_mutation(out.network, prior_probabilities.copy(), mutation_rate, 3)\n",
    "    ground_cm = get_character_matrix(leaves)\n",
    "    ground_cm.to_csv(path + '/ground_truth_cm' + str(i) + '.txt', sep = '\\t')\n",
    "    \n",
    "    overlay_heritable_dropout(out.network)\n",
    "    add_stochastic_leaves(leaves, dropout_rate, cassette_size)\n",
    "    dropout_cm = get_character_matrix(leaves)\n",
    "    dropout_cm = dropout_cm.astype(str)\n",
    "    row_names = ['c' + str(i) for i in range(dropout_cm.shape[0])]\n",
    "    dropout_cm.index = row_names\n",
    "    dropout_cm.to_csv(path + '/dropout_cm' + str(i) + '.txt', sep = '\\t')\n",
    "    pic.dump(out, open(path + '/dropout_net' + str(i) + '.pkl', 'wb'))\n",
    "    \n",
    "    num_dropped = 0\n",
    "    for k in range(dropout_cm.shape[0]):\n",
    "        for j in range(dropout_cm.shape[1]):\n",
    "            if dropout_cm.iloc[k,j] == \"-\" or dropout_cm.iloc[k,j] == \"*\":\n",
    "                num_dropped += 1\n",
    "    drop_perc.append(num_dropped/(dropout_cm.shape[0] * dropout_cm.shape[1]))\n",
    "    \n",
    "    num_leaves = len(leaves)\n",
    "    size.append(num_leaves)\n",
    "    \n",
    "    spc = states_per_char(dropout_cm)\n",
    "    avg_spc.append(sum(spc)/len(spc))\n",
    "\n",
    "#     count = count_all_dropouts_leaves(leaves)/(num_leaves*number_of_states)\n",
    "#     counts.append(count)\n",
    "    \n",
    "    print(i, num_leaves, sum(spc)/len(spc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2012195847616055\n",
      "0.20070501394030804\n",
      "5.841333333333333\n",
      "5.566666666666666\n",
      "391.24\n",
      "383.5\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "print(stat.mean(drop_perc))\n",
    "print(stat.median(drop_perc))\n",
    "print(stat.mean(avg_spc))\n",
    "print(stat.median(avg_spc))\n",
    "print(stat.mean(size))\n",
    "print(stat.median(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([size, heights, widths, avg_deg, avg_leaf_deg])\n",
    "df.index = [\"size\", \"heights\", \"widths\", \"avg_deg\", \"avg_leaf_deg\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path + '/tree_stats.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_mutation(out.network, prior_probabilities.copy(), (1 - .9999), 30)\n",
    "overlay_heritable_dropout(out.network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in out.network.nodes():\n",
    "    print(i.get_character_string())\n",
    "    print(out.network.nodes[i]['lifespan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_tree(network):\n",
    "    root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "    if network.out_degree(root) > 0:\n",
    "        for node in network.successors(root):\n",
    "            post_process_helper(network, node, root)\n",
    "    \n",
    "def post_process_helper(network, node, parent):\n",
    "    if parent.char_vec == node.char_vec:\n",
    "        succs = network.successors(node)\n",
    "        network.remove_node(node)\n",
    "        for i in succs:\n",
    "            network.add_edge(parent, i)\n",
    "            post_process_helper(network, i, parent)\n",
    "    else:\n",
    "        for i in network.successors(node):\n",
    "            post_process_helper(network, i, node)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
