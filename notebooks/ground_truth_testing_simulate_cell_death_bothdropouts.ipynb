{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pic\n",
    "import random\n",
    "\n",
    "import cassiopeia.TreeSolver.simulation_tools.simulation_utils as sim_utils\n",
    "import cassiopeia.TreeSolver.simulation_tools.dataset_generation as data_gen\n",
    "from cassiopeia.TreeSolver.Node import Node\n",
    "from cassiopeia.TreeSolver.Cassiopeia_Tree import Cassiopeia_Tree\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "\n",
    "#import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mutation(sample, mutation_prob_map):\n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        character = sample[i]\n",
    "        if character == '0':\n",
    "            values, probabilities = zip(*mutation_prob_map[i].items())\n",
    "            new_character = np.random.choice(values, p=probabilities)\n",
    "            new_sample.append(new_character)\n",
    "        else:\n",
    "            new_sample.append(character)\n",
    "    return new_sample\n",
    "\n",
    "def simulate_dropout(sample, variable_dropout_probability_map):\n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        if random.uniform(0, 1) <= variable_dropout_probability_map[i]:\n",
    "            new_sample.append('-')\n",
    "        else:\n",
    "            new_sample.append(sample[i])\n",
    "    return new_sample\n",
    "\n",
    "def get_character_matrix(nodes):\n",
    "    \n",
    "    char_arrays = []\n",
    "    for n in nodes:\n",
    "        chars = n.char_string.split(\"_\")[0].split(\"|\")\n",
    "        char_arrays.append(chars)\n",
    "        \n",
    "    return pd.DataFrame(char_arrays)\n",
    "\n",
    "def compute_priors(C, S, p, mean=0.01, disp=0.1, skew_factor = 0.05, num_skew=1, empirical = np.array([]), mixture = 0):\n",
    "    \n",
    "    sp = {}\n",
    "    prior_probabilities = {}\n",
    "    for i in range(0, C):\n",
    "        if len(empirical) > 0:\n",
    "            sampled_probabilities = sorted(empirical)\n",
    "        else:\n",
    "            sampled_probabilities = sorted([np.random.negative_binomial(mean,disp) for _ in range(1,S+1)])\n",
    "        s = C % num_skew\n",
    "        mut_rate = p * (1 + num_skew * skew_factor)\n",
    "        prior_probabilities[i] = {'0': (1-mut_rate)}\n",
    "        total = np.sum(sampled_probabilities)\n",
    "\n",
    "        sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "        \n",
    "        if mixture > 0: \n",
    "            for s in range(len(sampled_probabilities)):\n",
    "                if np.random.uniform() <= mixture:\n",
    "                    sampled_probabilities[s] = np.random.uniform()\n",
    "            \n",
    "            sp[i] = sampled_probabilities \n",
    "            total = np.sum(sampled_probabilities)\n",
    "            sampled_probabilities = list(map(lambda x: x / (1.0 * total), sampled_probabilities))\n",
    "            \n",
    "            \n",
    "        for j in range(1, S+1):\n",
    "            prior_probabilities[i][str(j)] = (mut_rate)*sampled_probabilities[j-1]\n",
    "\n",
    "    return prior_probabilities, sp\n",
    "\n",
    "def count_all_dropouts_leaves(leaves):\n",
    "    count = 0\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        for i in sample:\n",
    "            if (i == '-' or i == '*'):\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulated_ground_tree(mutation_prob_map, characters=10, depth=10, min_division_rate=0.8, cell_death=0.01):\n",
    "    network = nx.DiGraph()\n",
    "    current_depth = [[['0' for _ in range(0, characters)], '0']]\n",
    "    network.add_node(sim_utils.node_to_string(current_depth[0]))\n",
    "    uniq = 1\n",
    "    \n",
    "#     division_rate = min_division_rate+((1-min_division_rate)*np.random.random())\n",
    "    division_rate = min_division_rate\n",
    "    \n",
    "    for i in range(0, depth):\n",
    "        temp_current_depth = []\n",
    "        for node in current_depth:\n",
    "            if np.random.random() >= cell_death:\n",
    "                if np.random.random() <= division_rate:\n",
    "                    for _ in range(0,2):\n",
    "                        child_node = simulate_mutation(node[0], mutation_prob_map)\n",
    "                        temp_current_depth.append([child_node, uniq])\n",
    "                        network.add_edge(sim_utils.node_to_string(node), sim_utils.node_to_string([child_node, str(uniq)]))\n",
    "                        uniq +=1\n",
    "                else:\n",
    "                    child_node = simulate_mutation(node[0], mutation_prob_map)\n",
    "                    temp_current_depth.append([child_node, node[1]])\n",
    "                    network = nx.relabel_nodes(network, {sim_utils.node_to_string(node): sim_utils.node_to_string([child_node, node[1]])}, copy = False)\n",
    "            else:\n",
    "                curr_parent = sim_utils.node_to_string(node)\n",
    "                while network.out_degree(curr_parent) < 1 and network.in_degree(curr_parent) > 0:\n",
    "                    next_parent = list(network.predecessors(curr_parent))[0]\n",
    "                    network.remove_node(curr_parent)\n",
    "                    curr_parent = next_parent\n",
    "                \n",
    "        current_depth = temp_current_depth\n",
    "\n",
    "    rdict = {}\n",
    "    i = 0\n",
    "    for n in network.nodes:\n",
    "        nn = Node(\"StateNode\" + str(i), n.split(\"_\")[0].split(\"|\"), pid = n.split(\"_\")[1], is_target=False)\n",
    "        i += 1\n",
    "        rdict[n] = nn\n",
    "\n",
    "    network = nx.relabel_nodes(network, rdict)\n",
    "    \n",
    "#     source = [x for x in network.nodes() if network.in_degree(x)==0][0]\n",
    "\n",
    "#     max_depth = max(nx.shortest_path_length(network,source,node) for node in network.nodes())\n",
    "#     shortest_paths = nx.shortest_path_length(network,source)\n",
    "\n",
    "#     leaves = [x for x in network.nodes() if network.out_degree(x)==0 and network.in_degree(x) == 1 and shortest_paths[x] == max_depth]\n",
    "\n",
    "    leaves = [n for n in network if network.out_degree(n) == 0 and network.in_degree(n) == 1] \n",
    "    \n",
    "    state_tree = Cassiopeia_Tree('simulated', network = network)\n",
    "    return state_tree, leaves\n",
    "\n",
    "def hereditary_helper(network, node, dropout_probability_map, hereditary_drop_indices, counter):\n",
    "    \n",
    "    sample = node.get_character_string().split('|')\n",
    "    temp_drop_indices = hereditary_drop_indices.copy()\n",
    "    \n",
    "    new_sample = []\n",
    "    for i in range(0, len(sample)):\n",
    "        if i in hereditary_drop_indices:\n",
    "            new_sample.append('-')\n",
    "        elif np.random.sample() <= dropout_probability_map[i]:\n",
    "            new_sample.append('-')\n",
    "            temp_drop_indices.append(i)\n",
    "            counter[0] = counter[0] + 1\n",
    "        else:\n",
    "            new_sample.append(sample[i])\n",
    "    \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "    \n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            hereditary_helper(network, i, dropout_probability_map, temp_drop_indices, counter)\n",
    "\n",
    "def stochastic_helper(network, node, dropout_probability_map, counter):\n",
    "    sample = node.get_character_string().split('|')\n",
    "    new_sample = simulate_dropout(sample, dropout_probability_map)\n",
    "    \n",
    "    node.char_vec = new_sample\n",
    "    node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "    \n",
    "    if network.out_degree(node) > 0:\n",
    "        for i in network.successors(node):\n",
    "            stochastic_helper(network, i, dropout_probability_map, counter)\n",
    "            \n",
    "def stochastic_helper_leaves(leaves, dropout_probability_map, counter):\n",
    "    for node in leaves:\n",
    "        sample = node.get_character_string().split('|')\n",
    "        new_sample = simulate_dropout(sample, dropout_probability_map)\n",
    "    \n",
    "        node.char_vec = new_sample\n",
    "        node.char_string = '|'.join([str(c) for c in new_sample])\n",
    "        \n",
    "def states_per_char(cm):\n",
    "    unique_chars = [0 for n in range(0, cm.shape[1])]\n",
    "    seen = [[] for n in range(0, cm.shape[1])]\n",
    "    for j in range(0, cm.shape[1]):\n",
    "        for i in range(0,cm.shape[0]):\n",
    "            val = cm.iloc[i, j]\n",
    "            if val != '0' and val != '-' and val not in seen[j]:\n",
    "                unique_chars[j] += 1\n",
    "                seen[j].append(val)\n",
    "    return unique_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters. 'hdropout_percent' is a string that represents the dropout percent, for pathing purposes\n",
    "\n",
    "NUM_CELLS = 1500\n",
    "mut_rate = .015\n",
    "number_of_states = 100\n",
    "depth = 11\n",
    "number_of_characters = 30\n",
    "death_rate = 0.06\n",
    "s_dropout = 0.20\n",
    "h_dropout = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout_map = {\"0\": 0.00, \"1\": 0.01, \"2\": 0.02, \"3\": 0.03, \"4\": 0.04, \"5\": 0.05, \"7\": 0.07, \"10\": 0.10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.20087976539589442 341 9.066666666666666\n",
      "1 0.20797285835453774 393 10.766666666666667\n",
      "2 0.20476190476190476 434 11.733333333333333\n",
      "3 0.19663512092534174 317 7.533333333333333\n",
      "4 0.1947075208913649 359 9.2\n",
      "5 0.19725829725829727 462 11.8\n",
      "6 0.20479351032448379 452 11.566666666666666\n",
      "7 0.22758620689655173 464 12.533333333333333\n",
      "8 0.19705573080967403 317 8.266666666666667\n",
      "9 0.2021164021164021 378 9.9\n",
      "10 0.20540540540540542 370 9.333333333333334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-9c90b7fe40c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#     pic.dump(out, open('/data/yosef2/users/richardz/projects/dropout_testing/ground_truth_testing/ground_truth_tree' + str(i) + '.pkl', 'wb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_simulated_ground_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_probabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_division_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_death\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeath_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-4923029ac9fb>\u001b[0m in \u001b[0;36mgenerate_simulated_ground_tree\u001b[0;34m(mutation_prob_map, characters, depth, min_division_rate, cell_death)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdivision_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                         \u001b[0mchild_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_mutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_prob_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                         \u001b[0mtemp_current_depth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchild_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchild_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6f728e5f174f>\u001b[0m in \u001b[0;36msimulate_mutation\u001b[0;34m(sample, mutation_prob_map)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mcharacter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcharacter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmutation_prob_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mnew_character\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mnew_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_character\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for dropout_str in dropout_map:\n",
    "\n",
    "#     dropout = dropout_map[dropout_str]\n",
    "#     print(dropout_str)\n",
    "\n",
    "#     #Create dropout maps\n",
    "#     dropouts = pd.DataFrame(np.full((number_of_characters, 1), dropout, dtype=float))\n",
    "s_dropout_prob_map = {i: s_dropout for i in range(0,number_of_characters)}\n",
    "h_dropout_prob_map = {i: h_dropout for i in range(0,number_of_characters)}\n",
    "\n",
    "#Establish the path, and create it if it doesn't yet exist\n",
    "path = \"/data/yosef2/users/richardz/projects/Yule/benchmarking/test\"\n",
    "if os.path.exists(path) == False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "#Main loop for simulation\n",
    "counts = []\n",
    "size = []\n",
    "avg_spc = []\n",
    "for i in range(0, 50):\n",
    "\n",
    "    #Compute Priors and generate the simulated tree\n",
    "    prior_probabilities = compute_priors(number_of_characters, number_of_states, mut_rate, 5, 0.5, skew_factor=0.0, num_skew=1)[0]\n",
    "    out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=number_of_characters, depth=depth, min_division_rate= 0.7, cell_death = death_rate)\n",
    "    #     pic.dump(out, open('/data/yosef2/users/richardz/projects/dropout_testing/ground_truth_testing/ground_truth_tree' + str(i) + '.pkl', 'wb'))\n",
    "    while len(leaves) < 300 or len(leaves) > 500:\n",
    "        out, leaves = generate_simulated_ground_tree(prior_probabilities, characters=number_of_characters, depth=depth, min_division_rate= 0.8, cell_death = death_rate)\n",
    "        \n",
    "    network = out.get_network()\n",
    "    #     pic.dump(out, open(path + '/sim_net' + str(i) + '.pkl', 'wb'))\n",
    "    pic.dump(prior_probabilities, open(path + '/sim_net_priors' + str(i) + '.pkl', 'wb'))\n",
    "\n",
    "    #Save the ground truth character matrix\n",
    "    ground_cm = get_character_matrix(leaves)\n",
    "    ground_cm.to_csv(path + '/ground_truth_cm' + str(i) + '.txt', sep = '\\t')\n",
    "\n",
    "    #Introduce Stochastic Dropout\n",
    "    root = [n for n in network if network.in_degree(n) == 0][0]\n",
    "    counter = [0]\n",
    "    stochastic_helper_leaves(leaves, s_dropout_prob_map, counter)\n",
    "    counter2 = [0]\n",
    "    hereditary_helper(network, root, h_dropout_prob_map, [], counter2)\n",
    "\n",
    "    #Create the character matrix post dropout, giving names to the indeces\n",
    "    dropout_cm = get_character_matrix(leaves)\n",
    "    dropout_cm = dropout_cm.astype(str)\n",
    "    row_names = ['c' + str(i) for i in range(dropout_cm.shape[0])]\n",
    "    dropout_cm.index = row_names\n",
    "    dropout_cm.to_csv(path + '/dropout_cm' + str(i) + '.txt', sep = '\\t')\n",
    "    pic.dump(out, open(path + '/dropout_net' + str(i) + '.pkl', 'wb'))\n",
    "\n",
    "    #Count the dropout proportion and save it\n",
    "    num_leaves = len(leaves)\n",
    "    size.append(num_leaves)\n",
    "\n",
    "    count = count_all_dropouts_leaves(leaves)/(num_leaves*number_of_characters)\n",
    "    counts.append(count)\n",
    "    \n",
    "    spc = states_per_char(dropout_cm)\n",
    "    avg_spc.append(sum(spc)/len(spc))\n",
    "\n",
    "    print(i, count, num_leaves, sum(spc)/len(spc))\n",
    "\n",
    "# import csv\n",
    "\n",
    "# #Write the dropout proportions to CSV\n",
    "# with open('/data/yosef2/users/richardz/projects/dropout_testing/cell_death_testing_new_both/dropout_percentage' + dropout_str + '.csv', 'w') as csvFile:\n",
    "#     writer = csv.writer(csvFile)\n",
    "#     writer.writerow(counts)\n",
    "# csvFile.close()\n",
    "\n",
    "# with open('/data/yosef2/users/richardz/projects/dropout_testing/cell_death_testing_new_both/sample_size' + dropout_str + '.csv', 'w') as csvFile:\n",
    "#     writer = csv.writer(csvFile)\n",
    "#     writer.writerow(size)\n",
    "# csvFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.806666666666667\n",
      "5.85\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "print(stat.mean(avg_spc))\n",
    "print(stat.median(avg_spc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2018153573601391\n",
      "0.20166352228089635\n"
     ]
    }
   ],
   "source": [
    "print(stat.mean(counts))\n",
    "print(stat.median(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392.2\n",
      "391.5\n"
     ]
    }
   ],
   "source": [
    "print(stat.mean(size))\n",
    "print(stat.median(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
